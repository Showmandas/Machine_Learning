{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "para='''Lorem Ipsum is simply dummy text of the printing and typesetting industry. Lorem Ipsum has been the industry's standard dummy text ever since the 1500s, when an unknown printer took a galley of type and scrambled it to make a type specimen book. It has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessig the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=re.sub(r'\\[0-9*]\\]',' ',para)\n",
    "txt=re.sub(r'\\s+',' ',txt)   #Eliminate duplicate whitespaces using wildcards\n",
    "txt=txt.lower()\n",
    "txt=re.sub(r'\\d',' ',txt)\n",
    "txt=re.sub(r'\\s+',' ',txt)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lorem ipsum is simply dummy text of the printing and typesetting industry.', \"lorem ipsum has been the industry's standard dummy text ever since the s, when an unknown printer took a galley of type and scrambled it to make a type specimen book.\", 'it has survived not only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged.', 'it was popularised in the s with the release of letraset sheets containing lorem ipsum passages, and more recently with desktop publishing software like aldus pagemaker including versions of lorem ipsum.']\n"
     ]
    }
   ],
   "source": [
    "sentences=nltk.sent_tokenize(txt)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['lorem', 'ipsum', 'is', 'simply', 'dummy', 'text', 'of', 'the', 'printing', 'and', 'typesetting', 'industry', '.'], ['lorem', 'ipsum', 'has', 'been', 'the', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', 'the', 's', ',', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', '.'], ['it', 'has', 'survived', 'not', 'only', 'five', 'centuries', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.'], ['it', 'was', 'popularised', 'in', 'the', 's', 'with', 'the', 'release', 'of', 'letraset', 'sheets', 'containing', 'lorem', 'ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'aldus', 'pagemaker', 'including', 'versions', 'of', 'lorem', 'ipsum', '.']]\n"
     ]
    }
   ],
   "source": [
    "sentences=[nltk.word_tokenize(sent) for sent in sentences]\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['lorem', 'ipsum', 'simply', 'dummy', 'text', 'printing', 'typesetting', 'industry', '.'], ['lorem', 'ipsum', 'has', 'been', 'the', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', 'the', 's', ',', 'when', 'an', 'unknown', 'printer', 'took', 'a', 'galley', 'of', 'type', 'and', 'scrambled', 'it', 'to', 'make', 'a', 'type', 'specimen', 'book', '.'], ['it', 'has', 'survived', 'not', 'only', 'five', 'centuries', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.'], ['it', 'was', 'popularised', 'in', 'the', 's', 'with', 'the', 'release', 'of', 'letraset', 'sheets', 'containing', 'lorem', 'ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'aldus', 'pagemaker', 'including', 'versions', 'of', 'lorem', 'ipsum', '.']]\n",
      "[['lorem', 'ipsum', 'simply', 'dummy', 'text', 'printing', 'typesetting', 'industry', '.'], ['lorem', 'ipsum', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', ',', 'unknown', 'printer', 'took', 'galley', 'type', 'scrambled', 'make', 'type', 'specimen', 'book', '.'], ['it', 'has', 'survived', 'not', 'only', 'five', 'centuries', ',', 'but', 'also', 'the', 'leap', 'into', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.'], ['it', 'was', 'popularised', 'in', 'the', 's', 'with', 'the', 'release', 'of', 'letraset', 'sheets', 'containing', 'lorem', 'ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'aldus', 'pagemaker', 'including', 'versions', 'of', 'lorem', 'ipsum', '.']]\n",
      "[['lorem', 'ipsum', 'simply', 'dummy', 'text', 'printing', 'typesetting', 'industry', '.'], ['lorem', 'ipsum', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', ',', 'unknown', 'printer', 'took', 'galley', 'type', 'scrambled', 'make', 'type', 'specimen', 'book', '.'], ['survived', 'five', 'centuries', ',', 'also', 'leap', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.'], ['it', 'was', 'popularised', 'in', 'the', 's', 'with', 'the', 'release', 'of', 'letraset', 'sheets', 'containing', 'lorem', 'ipsum', 'passages', ',', 'and', 'more', 'recently', 'with', 'desktop', 'publishing', 'software', 'like', 'aldus', 'pagemaker', 'including', 'versions', 'of', 'lorem', 'ipsum', '.']]\n",
      "[['lorem', 'ipsum', 'simply', 'dummy', 'text', 'printing', 'typesetting', 'industry', '.'], ['lorem', 'ipsum', 'industry', \"'s\", 'standard', 'dummy', 'text', 'ever', 'since', ',', 'unknown', 'printer', 'took', 'galley', 'type', 'scrambled', 'make', 'type', 'specimen', 'book', '.'], ['survived', 'five', 'centuries', ',', 'also', 'leap', 'electronic', 'typesetting', ',', 'remaining', 'essentially', 'unchanged', '.'], ['popularised', 'release', 'letraset', 'sheets', 'containing', 'lorem', 'ipsum', 'passages', ',', 'recently', 'desktop', 'publishing', 'software', 'like', 'aldus', 'pagemaker', 'including', 'versions', 'lorem', 'ipsum', '.']]\n"
     ]
    }
   ],
   "source": [
    "# eliminate stopwords from data\n",
    "for i in range(len(sentences)):\n",
    "    sentences[i]=[word for word  in sentences[i] if word  not in  stopwords.words('english')]\n",
    "    print(sentences)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Word2Vec(sentences,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mf:\\nlp\\TextPreprocessing\\Word2Vec.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/nlp/TextPreprocessing/Word2Vec.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#find vocabulary\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/nlp/TextPreprocessing/Word2Vec.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m vocab_words\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39;49mwv\u001b[39m.\u001b[39;49mvocab\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\gensim\\models\\keyedvectors.py:735\u001b[0m, in \u001b[0;36mKeyedVectors.vocab\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    734\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvocab\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 735\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    736\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe vocab attribute was removed from KeyedVector in Gensim 4.0.0.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse KeyedVector\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms .key_to_index dict, .index_to_key list, and methods \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    738\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m.get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    740\u001b[0m     )\n",
      "\u001b[1;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ]
    }
   ],
   "source": [
    "#find vocabulary\n",
    "vocab_words=model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00714011  0.00123272 -0.00717275 -0.00225149  0.00371838  0.00581718\n",
      "  0.00119681  0.0021259  -0.00409239  0.00719593 -0.006285    0.0046467\n",
      " -0.00822815  0.00203882 -0.00497781 -0.00424991 -0.00310158  0.00564871\n",
      "  0.00580421 -0.00497637  0.00076971 -0.00848784  0.00782417  0.00925486\n",
      " -0.00274284  0.0007957   0.00074471  0.00550156 -0.00861197  0.00058686\n",
      "  0.00687825  0.00222064  0.0011353  -0.00933806  0.00848342 -0.00626396\n",
      " -0.0029891   0.00347539 -0.00078275  0.00141478  0.00177903 -0.00682556\n",
      " -0.00973399  0.00903108  0.00620797 -0.0069212   0.00340988  0.00020138\n",
      "  0.00476106 -0.00710549  0.00404204  0.00434489  0.00994589 -0.00447871\n",
      " -0.0013828  -0.00731804 -0.00968667 -0.00906813 -0.00101885 -0.00650191\n",
      "  0.00483703 -0.00615188  0.00254129  0.00073761 -0.00340562 -0.00096849\n",
      "  0.0099766   0.00914634 -0.00447836  0.00908198 -0.005625    0.00593513\n",
      " -0.00307769  0.00343221  0.00302344  0.00688967 -0.00237185  0.0087658\n",
      "  0.0075704  -0.0095462  -0.00802714 -0.00763374  0.0029102  -0.0027743\n",
      " -0.00693061 -0.0081337   0.00831546  0.00198992 -0.00932511 -0.00477882\n",
      "  0.00313612 -0.00470607  0.00528776 -0.00423707  0.00265934 -0.00804599\n",
      "  0.00621902  0.00482679  0.00078735  0.00299899]\n"
     ]
    }
   ],
   "source": [
    "#finding word vector\n",
    "vector_wrd=model.wv['dummy']\n",
    "print(vector_wrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('took', 0.2526387870311737), ('pagemaker', 0.2007426917552948), ('popularised', 0.19530975818634033), ('publishing', 0.17534568905830383), ('.', 0.17017371952533722), ('galley', 0.15079423785209656), ('release', 0.14548979699611664), ('text', 0.13875731825828552), ('since', 0.10845551639795303), ('simply', 0.09949549287557602)]\n"
     ]
    }
   ],
   "source": [
    "similar_wrd=model.wv.most_similar('dummy')\n",
    "print(similar_wrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
