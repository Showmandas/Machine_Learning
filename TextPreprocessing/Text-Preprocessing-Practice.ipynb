{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('indian_food.csv')\n",
    "df=df.drop(columns=['course','state','region','diet','prep_time','cook_time','flavor_profile'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balu shahi</td>\n",
       "      <td>Maida flour, yogurt, oil, sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boondi</td>\n",
       "      <td>Gram flour, ghee, sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gajar ka halwa</td>\n",
       "      <td>Carrots, milk, sugar, ghee, cashews, raisins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ghevar</td>\n",
       "      <td>Flour, ghee, kewra, milk, clarified butter, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gulab jamun</td>\n",
       "      <td>Milk powder, plain flour, baking powder, ghee,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                        ingredients\n",
       "0      Balu shahi                    Maida flour, yogurt, oil, sugar\n",
       "1          Boondi                            Gram flour, ghee, sugar\n",
       "2  Gajar ka halwa       Carrots, milk, sugar, ghee, cashews, raisins\n",
       "3          Ghevar  Flour, ghee, kewra, milk, clarified butter, su...\n",
       "4     Gulab jamun  Milk powder, plain flour, baking powder, ghee,..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        Maida flour, yogurt, oil, sugar\n",
       "1                                Gram flour, ghee, sugar\n",
       "2           Carrots, milk, sugar, ghee, cashews, raisins\n",
       "3      Flour, ghee, kewra, milk, clarified butter, su...\n",
       "4      Milk powder, plain flour, baking powder, ghee,...\n",
       "                             ...                        \n",
       "250              Glutinous rice, black sesame seeds, gur\n",
       "251    Coconut milk, egg yolks, clarified butter, all...\n",
       "252    Cottage cheese, dry dates, dried rose petals, ...\n",
       "253    Milk powder, dry fruits, arrowroot powder, all...\n",
       "254    Brown rice, fennel seeds, grated coconut, blac...\n",
       "Name: ingredients, Length: 255, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ingredients']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flour, ghee, kewra, milk, clarified butter, sugar, almonds, pistachio, saffron, green cardamom'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ingredients[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowecasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>lowerCase_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balu shahi</td>\n",
       "      <td>Maida flour, yogurt, oil, sugar</td>\n",
       "      <td>maida flour, yogurt, oil, sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boondi</td>\n",
       "      <td>Gram flour, ghee, sugar</td>\n",
       "      <td>gram flour, ghee, sugar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gajar ka halwa</td>\n",
       "      <td>Carrots, milk, sugar, ghee, cashews, raisins</td>\n",
       "      <td>carrots, milk, sugar, ghee, cashews, raisins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ghevar</td>\n",
       "      <td>Flour, ghee, kewra, milk, clarified butter, su...</td>\n",
       "      <td>flour, ghee, kewra, milk, clarified butter, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gulab jamun</td>\n",
       "      <td>Milk powder, plain flour, baking powder, ghee,...</td>\n",
       "      <td>milk powder, plain flour, baking powder, ghee,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                        ingredients  \\\n",
       "0      Balu shahi                    Maida flour, yogurt, oil, sugar   \n",
       "1          Boondi                            Gram flour, ghee, sugar   \n",
       "2  Gajar ka halwa       Carrots, milk, sugar, ghee, cashews, raisins   \n",
       "3          Ghevar  Flour, ghee, kewra, milk, clarified butter, su...   \n",
       "4     Gulab jamun  Milk powder, plain flour, baking powder, ghee,...   \n",
       "\n",
       "                                      lowerCase_text  \n",
       "0                    maida flour, yogurt, oil, sugar  \n",
       "1                            gram flour, ghee, sugar  \n",
       "2       carrots, milk, sugar, ghee, cashews, raisins  \n",
       "3  flour, ghee, kewra, milk, clarified butter, su...  \n",
       "4  milk powder, plain flour, baking powder, ghee,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.ingredients[3].lower()\n",
    "df['lowerCase_text']=df['ingredients'].str.lower() #create new column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flour ghee kewra milk clarified butter sugar almonds pistachio saffron green cardamom\n"
     ]
    }
   ],
   "source": [
    "data_ingredients=df.ingredients[3]\n",
    "def remove_punc(text):\n",
    "    punc_rem=\"\".join([p for p in text if p not in string.punctuation])\n",
    "    return punc_rem \n",
    "\n",
    "print(remove_punc(data_ingredients))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flour', 'ghee', 'kewra', 'milk', 'clarified', 'butter', 'sugar', 'almonds', 'pistachio', 'saffron', 'green', 'cardamom']\n"
     ]
    }
   ],
   "source": [
    "data_ingredients=df.ingredients[3]\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "def tokenize_word(text):\n",
    "      punc_rem=\"\".join([p for p in text if p not in string.punctuation]) \n",
    "      token_word=word_tokenize(punc_rem)\n",
    "      return token_word\n",
    "\n",
    "print(tokenize_word(data_ingredients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop word remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'l', 'u', 'r', ',', ' ', 'g', 'h', 'e', 'e', ',', ' ', 'k', 'e', 'w', 'r', ',', ' ', 'l', 'k', ',', ' ', 'c', 'l', 'r', 'f', 'e', ' ', 'b', 'u', 'e', 'r', ',', ' ', 'u', 'g', 'r', ',', ' ', 'l', 'n', ',', ' ', 'p', 'c', 'h', ',', ' ', 'f', 'f', 'r', 'n', ',', ' ', 'g', 'r', 'e', 'e', 'n', ' ', 'c', 'r']\n"
     ]
    }
   ],
   "source": [
    "data_ingredients=df.ingredients[3]\n",
    "eng_stopwords=stopwords.words('english')\n",
    "def remove_stop_words(text):\n",
    "    rem_st_words=[word for word in text if word not in eng_stopwords]\n",
    "    return rem_st_words\n",
    "print(remove_stop_words(data_ingredients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "word_portemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flour', 'ghee', 'kewra', 'milk', 'clarifi', 'butter', 'sugar', 'almond', 'pistachio', 'saffron', 'green', 'cardamom']\n"
     ]
    }
   ],
   "source": [
    "token=tokenize_word(data_ingredients)\n",
    "def stem_words(text):\n",
    "    word_stem=[word_portemmer.stem(word) for word in text]\n",
    "    return word_stem\n",
    "\n",
    "print(stem_words(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flour', 'ghee', 'kewra', 'milk', 'clarifi', 'butter', 'sugar', 'almond', 'pistachio', 'saffron', 'green', 'cardamom']\n"
     ]
    }
   ],
   "source": [
    "token=tokenize_word(data_ingredients)\n",
    "stem=stem_words(token)\n",
    "def lemmatize_word(text):\n",
    "    word_lemma=[word_lemmatizer.lemmatize(word) for word in text]\n",
    "    return word_lemma\n",
    "print(lemmatize_word(stem_words(token)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
